{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "standing-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alien-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_pages_of_10(url_list_10):\n",
    "    url_list = []\n",
    "    for page_number in range(0,11):\n",
    "        #remember that the end is ?page=\n",
    "        url_page = url_list_10+str(page_number)\n",
    "        url_list.append(url_page)\n",
    "    return url_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unsigned-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_10pages = get_list_pages_of_10('https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century?page=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "geographic-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_for_100(url_one_page):\n",
    "    url_page = requests.get(url_one_page)\n",
    "    soup = BeautifulSoup(url_page.content, 'html.parser')\n",
    "    href_link_list =[]\n",
    "    for link in soup.find_all('a', class_='bookTitle') :\n",
    "        if link.has_attr('href'):\n",
    "            href_link_list.append(\"https://www.goodreads.com\" + str(link.attrs['href']))\n",
    "    return href_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unauthorized-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_100_links = get_links_for_100('https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century?page=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "diverse-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "https://www.goodreads.com/book/show/4671.The_Great_Gatsby\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_100_links))\n",
    "print(list_of_100_links[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "educated-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get title\n",
    "def get_title(soup_detail):\n",
    "    try:\n",
    "        title = soup_detail.find(\"h1\", {\"id\":\"bookTitle\"}).text.replace(\"\\n\",\"\").replace(\"      \",\"\")\n",
    "    except:\n",
    "        title = np.nan\n",
    "    return title\n",
    "\n",
    "# get author\n",
    "def get_author(soup_detail):\n",
    "    try:\n",
    "        author = soup_detail.find(\"div\", {\"class\":\"authorName__container\"}).text.replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        author = np.nan\n",
    "    return author\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get ratings\n",
    "def get_rating(soup_detail):\n",
    "    try:\n",
    "        rating = soup_detail.find(\"meta\", {\"itemprop\":\"ratingCount\"}).text.replace(\"\\n\",\"\").split()\n",
    "        rating = rating[0]        \n",
    "    except:\n",
    "        rating = np.nan      \n",
    "    return rating\n",
    "\n",
    "\n",
    "# get avgratings\n",
    "book_avgratings = []\n",
    "def get_avgrating(soup_detail):\n",
    "    try:\n",
    "        avgrating = soup_detail.find(\"span\", {\"itemprop\":\"ratingValue\"}).text.replace(\"\\n\",\"\").replace(' ','')\n",
    "    except:\n",
    "        avgrating = np.nan\n",
    "    return avgrating\n",
    "\n",
    "# get pages\n",
    "book_pages = []\n",
    "def get_page(soup_detail):\n",
    "    try:\n",
    "        page = soup_detail.find(\"span\", {\"itemprop\":\"numberOfPages\"}).text.split()\n",
    "        page = page[0]\n",
    "    except:\n",
    "        page = np.nan\n",
    "    return page\n",
    "\n",
    "\n",
    "# get years\n",
    "book_publish_year = []\n",
    "def get_year(soup_detail):\n",
    "    try:\n",
    "        publish_year = soup_detail.find(\"nobr\", {\"class\":\"greyText\"}).text.replace(\"\\n\",\"\").replace(\")\",\"\").split()\n",
    "        publish_year = publish_year[-1]\n",
    "    except:\n",
    "        publish_year = np.nan\n",
    "    return publish_year\n",
    "\n",
    "# get award\n",
    "def get_award(soup_detail):\n",
    "    try:\n",
    "        award = soup_detail.find(\"div\", {\"itemprop\":\"awards\"}).text.replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        award = np.nan\n",
    "    return award\n",
    "\n",
    "# get genres\n",
    "def get_genres(soup_detail):\n",
    "    try:\n",
    "        genres = soup_detail.find_all(class_=\"actionLinkLite bookPageGenreLink\")\n",
    "        genres = genres[:3]\n",
    "        genres = [genre.get_text() for genre in genres]\n",
    "    except:\n",
    "        genres = np.nan\n",
    "    return genres\n",
    "\n",
    "#get the book reviews\n",
    "def get_review(soup_detail):\n",
    "    try:\n",
    "        review = soup_detail.find(\"meta\", {\"itemprop\":\"reviewCount\"}).text.replace(\"\\n\",\"\").split()\n",
    "        review = review[0]\n",
    "    except:\n",
    "        review = np.nan\n",
    "    return review\n",
    "\n",
    "# get series\n",
    "def get_series(soup_detail):\n",
    "    try:\n",
    "        series = soup_detail.find(id=\"bookSeries\").text.strip()\n",
    "        if len(series) == 0:\n",
    "            series = False\n",
    "        else: \n",
    "            series = True\n",
    "    except:\n",
    "        series = np.nan\n",
    "    return series\n",
    "\n",
    "# get places\n",
    "def get_places(soup_detail):\n",
    "    try:\n",
    "        places = soup_detail.find(\"div\", {'id':\"bookDataBox\"}).find('span',class_=\"darkGreyText\").text.replace(\"(\",\"\").replace(\")\",\"\").strip()\n",
    "    except:\n",
    "        places = np.nan\n",
    "    return places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "neither-large",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-6e90d49e1c2f>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-6e90d49e1c2f>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    data = ['url' : url_list,\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_df_and_save_as_csv(url_list):\n",
    "    title = []\n",
    "    author = []\n",
    "    num_reviews = []\n",
    "    num_ratings = []\n",
    "    avg_rating = []\n",
    "    num_pages = []\n",
    "    original_publish_year = []\n",
    "    series = []\n",
    "    genres = []\n",
    "    awards = []\n",
    "    places = []\n",
    " \n",
    "    for link in url_list:\n",
    "        one_book= requests.get(link)\n",
    "        soup_detail = BeautifulSoup(one_book.content, 'html.parser')\n",
    "    \n",
    "    ####\n",
    "        title.append(get_title(soup_detail))\n",
    "        author.append(get_author(soup_detail))\n",
    "        num_reviews.append(get_review(soup_detail))\n",
    "        num_ratings.append(get_rating(soup_detail))\n",
    "        avg_rating.append(get_avgrating(soup_detail))\n",
    "        num_pages.append(get_page(soup_detail))\n",
    "        original_publish_year.append(get_year(soup_detail))\n",
    "        series.append(get_series(soup_detail))\n",
    "        genres.append(get_genres(soup_detail))\n",
    "        awards.append(get_award(soup_detail))\n",
    "        places.append(get_places(soup_detail))\n",
    "        \n",
    "    data = {'url' : url_list,\n",
    "            'title':title,\n",
    "            'author':author,\n",
    "            'num_reviews':num_reviews,\n",
    "            'num_ratings': num_ratings,\n",
    "            'avg_rating':avg_rating,\n",
    "            'num_pages'_num_page,\n",
    "            'original_publish_year':original_publish_year,\n",
    "            'series':series,\n",
    "            'genres':genres,\n",
    "            'awards':awards,\n",
    "            'places':places\n",
    "           }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"df_new_100.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "personalized-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_df_and_save_as_csv(list_of_100_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-restaurant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adjusted-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = ['url','title','author','num_reviews','num_ratings','avg_rating','num_pages',\n",
    "                   'original_publish_year',\n",
    "                   'series',\n",
    "                   'genres',\n",
    "                   'awards',\n",
    "                   'places'\n",
    "                          ]\n",
    "df = pd.DataFrame(columns=list_of_columns)\n",
    "df['url'] = url_of_100\n",
    "df['title'] = title \n",
    "df['author'] = author \n",
    "df['num_reviews'] = num_reviews \n",
    "df['num_ratings'] =  num_ratings\n",
    "df['avg_rating'] = avg_rating\n",
    "df['num_pages'] = num_pages\n",
    "df['original_publish_year'] =  original_publish_year\n",
    "df['series'] = series\n",
    "df['genres'] = genres\n",
    "df['awards'] = awards\n",
    "df['places'] = places\n",
    "\n",
    "df.to_csv(\"df_all_100.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
